{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processFiles(fname):\n",
    "    \n",
    "#     creating dictionary to story various classes\n",
    "    dict_corpus = {0:[],1:[]}\n",
    "    \n",
    "#     put various files in a list to continously read files\n",
    "    for i in fname:\n",
    "        with open (i, \"r\") as openedFile:\n",
    "            for line in openedFile:\n",
    "                lineSplit = line.strip('\\n').split('\\t')\n",
    "                \n",
    "#                 print(lineSplit)\n",
    "                if len(lineSplit) > 1 and int(lineSplit[1]) == 0:\n",
    "                    lineSplitFormat = ''.join(lineSplit[0]).lower()\n",
    "                    lineSplitFormat = re.sub(r'[,.:!+&$?;\"\"()''/|]', '', lineSplitFormat)\n",
    "                    dict_corpus[0].append(lineSplitFormat.split())\n",
    "                else:\n",
    "                    lineSplitFormat = ''.join(lineSplit[0]).lower()\n",
    "                    lineSplitFormat = re.sub(r'[,.:!+&$?;\"\"()''/|]', '', lineSplitFormat)\n",
    "                    dict_corpus[1].append(lineSplitFormat.split())\n",
    "\n",
    "#     print(dict_corpus[1])\n",
    "    return dict_corpus\n",
    "\n",
    "# globally accessed\n",
    "name= [\"amazon_cells_labelled.txt\", \"imdb_labelled.txt\", \"yelp_labelled.txt\"]\n",
    "dict_corpus=processFiles(name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 1500 3000\n",
      "{0: -0.6931471805599453, 1: -0.6931471805599453}\n"
     ]
    }
   ],
   "source": [
    "# This function calculates the log_prior of the two classes positive(1) and negative(0)\n",
    "\n",
    "def calculate_logprior(dict_corpus):\n",
    "    positive_class = len(dict_corpus[1])\n",
    "    negative_class = len(dict_corpus[0])\n",
    "    num_documents = positive_class + negative_class\n",
    "    \n",
    "    log_prior = {0:math.log(negative_class/num_documents), 1:math.log(positive_class/num_documents)}\n",
    "    \n",
    "    print (positive_class, negative_class, num_documents)\n",
    "    print(log_prior)\n",
    "    return positive_class,negative_class,log_prior\n",
    "    \n",
    "\n",
    "positive_class,negative_class,log_prior=calculate_logprior(dict_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3370\n",
      "5473\n"
     ]
    }
   ],
   "source": [
    "def calculate_loglikelihood(dict_corpus):\n",
    "    \n",
    "# creating a dictionary to store the number of occurences her word in each class\n",
    "    wordCountPositive= {}\n",
    "    wordCountNegative= {}\n",
    "    denominator= {}\n",
    "    vocab = []\n",
    "    \n",
    "# counting the word occurrences in the negative review dictionary\n",
    "    for review in dict_corpus[0]:\n",
    "        for word in review:\n",
    "            wordCountNegative[word] = wordCountNegative.get(word, 0) + 1\n",
    "                \n",
    "# counting the word occurrences in the positive review dictionary\n",
    "# for each review in my positive dictionary\n",
    "    for review in dict_corpus[1]:\n",
    "        for word in review:\n",
    "            wordCountPositive[word]= wordCountPositive.get(word, 0) +1\n",
    "                \n",
    "#     print(wordCountPositive)\n",
    "    print(len(wordCountNegative.keys()))\n",
    "\n",
    "#     print(wordCountNegative)\n",
    "\n",
    "# the vocab is all the individual words in the dict corpus\n",
    "# returns a distinct/unique words because we wrapped in the collection \"set\"\n",
    "    vocab = set(list(wordCountPositive.keys())+ list(wordCountNegative.keys()))\n",
    "    print(len(vocab))\n",
    "  \n",
    "    countPos = 0\n",
    "    countNeg = 0\n",
    "    for word in vocab:\n",
    "        countPos+=wordCountPositive.get(word, 0) + 1\n",
    "    denominator[1] = countPos\n",
    "    \n",
    "    for word in vocab:\n",
    "        countNeg+=wordCountNegative.get(word, 0) + 1\n",
    "    denominator[0] = countNeg\n",
    "    \n",
    "#     print(denominator)\n",
    "    \n",
    "    return wordCountPositive, wordCountNegative, denominator, vocab\n",
    "\n",
    "wordCountPositive, wordCountNegative, denominator, vocab = calculate_loglikelihood(dict_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function predicts the class of a sentence\n",
    "\n",
    "def predictsentence(test_sentence):\n",
    "    sum= {0: 0 , 1:0 }\n",
    "    \n",
    "    for word in test_sentence.split():\n",
    "        loglikehood_positive = math.log((wordCountPositive.get(word, 0)+1)/denominator[1])\n",
    "        loglikehood_negative = math.log((wordCountNegative.get(word, 0)+1)/denominator[0])\n",
    "        sum[1]+=loglikehood_positive\n",
    "        sum[0]+= loglikehood_negative\n",
    "        \n",
    "# added the value of the log prior to the log likelihood    \n",
    "    sum[0] = sum[0] + log_prior[0]\n",
    "    sum[1] = sum[1] + log_prior[1]\n",
    "    \n",
    "#     print(log_prior)\n",
    "\n",
    "# Determining the class of the sentence\n",
    "    if sum[1] > sum[0]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "            \n",
    "predictsentence(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This function predicts the class of a document.\n",
    "# It utilises the function predictSentence above to predict individual sentences in a text file\n",
    "def predictDocKnownLabels(testdoc, results):\n",
    "    computed = []\n",
    "    knownLabel = []\n",
    "    \n",
    "    with open (testdoc, \"r\") as openedTestdoc,open (results, \"w\", newline = \"\") as openedresultdoc:\n",
    "            for line in openedTestdoc:\n",
    "                lineSplitFormat = ''.join(line).lower()\n",
    "                lineSplitFormat = re.sub(r'[,.:!+<>&$?;\"\"()''/|]', '', lineSplitFormat)\n",
    "                \n",
    "#               this splits by tab and strips the newline character and return a list of reviews and their labels\n",
    "                x= lineSplitFormat.strip('\\n').split('\\t')\n",
    "#                 print(x)\n",
    "                \n",
    "#               append the label of the various reviews as an integer and append to my knownLabel list\n",
    "                knownLabel.append(int(x[1]))\n",
    "    \n",
    "#               call the function predictSentence and pass in only the reviews\n",
    "                label = predictsentence(x[0])\n",
    "            \n",
    "#               append the predicted  labels to the list computed\n",
    "                computed.append(label)\n",
    "    \n",
    "#               write to the results file the predicted labels\n",
    "                openedresultdoc.write(str(label) + \"\\n\")\n",
    "            \n",
    "#             print(knownLabel)\n",
    "#             print(computed)\n",
    "            return computed, knownLabel\n",
    "                \n",
    "knownLabel,computed  = predictDocKnownLabels(\"yelp_labelled.txt\", \"results.txt\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function calculates for the accuracy of the predictions\n",
    "# This builds up on the function predictUnknown\n",
    "\n",
    "def accuracy(knownLabel, computed):\n",
    "    correct = 0\n",
    "    for i in range(len(knownLabel)):\n",
    "        if knownLabel[i] == computed[i]:\n",
    "            correct+=1\n",
    "            \n",
    "#print statement \n",
    "    accuracy = round((correct/ len(knownLabel)) *100, 2) \n",
    "#     print(\"Accuracy:\" , accuracy )\n",
    "            \n",
    "    return accuracy\n",
    "                \n",
    "accuracy(knownLabel, computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function predicts the class of a document with unknown labels.\n",
    "# It utilises the function predictSentence above to predict individual sentences in a text file\n",
    "def predictDocUnknownLabels(testdoc, results):\n",
    "    \n",
    "    with open (testdoc, \"r\") as openedTestdoc,open (results, \"w\", newline = \"\") as openedresultdoc:\n",
    "            for line in openedTestdoc:\n",
    "                lineSplitFormat = ''.join(line).lower()\n",
    "#                 print(lineSplitFormat)\n",
    "                lineSplitFormat = re.sub(r'[,.:!+<>&$?;\"\"()''/|]', '', lineSplitFormat)\n",
    "                \n",
    "#               call the function predictSentence and pass in only the reviews\n",
    "                label = predictsentence(lineSplitFormat)\n",
    "#                 print(label)\n",
    "    \n",
    "#               write to the results file the predicted labels\n",
    "                openedresultdoc.write(str(label) + \"\\n\")\n",
    "\n",
    "# To test this Naive Bayes classifier, relapce testdoc.txt with intended test file               \n",
    "predictDocUnknownLabels(\"testdoc.txt\", \"results.txt\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
